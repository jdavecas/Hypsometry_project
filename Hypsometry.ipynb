{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from pathlib import Path\n",
    "import folium\n",
    "from folium import plugins\n",
    "import mapclassify\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob \n",
    "import plotly.graph_objects as go\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current working directory\n",
    "#os.chdir(\"..\") Used only fto go down one directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the shapefiles in the directory and split them into nodes and reaches\n",
    "shpNd = glob.glob('SWOT_L2_HR_RiverSP/**/*Node*.shp', recursive=True) #Nodes\n",
    "shpRch = glob.glob('SWOT_L2_HR_RiverSP/**/*Reach*.shp', recursive=True) #Reaches\n",
    "shpNd,shpRch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpNd_022_NA = glob.glob('SWOT_L2_HR_RiverSP/**/*Node*_022_NA*.shp', recursive=True) #Nodes\n",
    "shpNd_022_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodataframes = []\n",
    "for i in range(len(shpNd_022_NA)):\n",
    "   geodataframes.append(gpd.read_file(shpNd_022_NA[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetted_dataframes = []\n",
    "\n",
    "# Loop over the list of dataframes\n",
    "for dataframe in geodataframes:\n",
    "\n",
    "    # Subset the dataframe to the desired columns and append to the list\n",
    "    subsetted_dataframes.append(dataframe[['node_id', 'lat', 'lon', 'river_name', 'wse', 'width']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_list = []\n",
    "\n",
    "# Number of rows in each dataframe (assuming they all have the same number of rows)\n",
    "num_rows = len(subsetted_dataframes[0])\n",
    "\n",
    "# Iterate over each row index\n",
    "for i in range(num_rows):\n",
    "    # Create a list to store data from each dataframe for the current row\n",
    "    row_data = []\n",
    "    # Iterate over each dataframe and extract the row data\n",
    "    for df in subsetted_dataframes:\n",
    "        row_data.append(df.iloc[i])\n",
    "    # Concatenate the row data into a single dataframe and append it to the result list\n",
    "    result_df_list.append(pd.concat(row_data, axis=1).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot scatter plot from a given dataframe\n",
    "def plot_scatter(dfa):\n",
    "    plot.scatter(dfa['width'], dfa['wse'])\n",
    "    plot.xlabel('width')\n",
    "    plot.ylabel('wse')\n",
    "    plot.title('Node id: ' + df['node_id'].iloc[0])\n",
    "    plot.show()\n",
    "\n",
    "# Select the index of the dataframe you want to plot\n",
    "df_index = 1237\n",
    "\n",
    "# Plot scatter plot for the selected dataframe\n",
    "plot_scatter(result_df_list[df_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_list[1236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(94/382.90, 93/382.73, 95/382.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames={}\n",
    "for i in range(len(shpNd_022_NA)):\n",
    "        frames[i] = pd.concat([gpd.read_file(shpNd_022_NA[i]).get('node_id'), gpd.read_file(shpNd_022_NA[i]).get('river_name'), gpd.read_file(shpNd_022_NA[i]).get('lat'), \n",
    "        gpd.read_file(shpNd_022_NA[i]).get('lon'), gpd.read_file(shpNd_022_NA[i]).get('wse'), gpd.read_file(shpNd_022_NA[i]).get('width')], axis=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rows = [frames.iloc[0] for frames in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the shapefile. [0] is used to read the first shapefile in the list\n",
    "gpd.read_file(shpNd[1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gpd.read_file(shpNd[0]).explore('wse', cmap='viridis', legend=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWOT_HR_shp1 = gpd.read_file(shpNd[0])[['river_name','p_wse','p_width','geometry']]\n",
    "SWOT_HR_shp1 =SWOT_HR_shp1.rename(columns={'river_name': 'River Name','p_wse':'Water Surface Elevation','p_width':'River Width'})\n",
    "SWOT_HR_shp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = SWOT_HR_shp1\n",
    "updated_m = L.explore(column='Water Surface Elevation', cmap='viridis', legend=True)\n",
    "\n",
    "updated_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.crs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"**/*\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes =   glob.glob(os.path.join('SWOT_L2_HR_RiverSP','*','*.shp'))\n",
    "list_of_dfs = []\n",
    "for f in shapes:\n",
    "    df = gpd.read_file(f)\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "list_of_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypsometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
