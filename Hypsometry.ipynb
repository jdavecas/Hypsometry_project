{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from pathlib import Path\n",
    "import folium\n",
    "from folium import plugins\n",
    "import mapclassify\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob \n",
    "import plotly.graph_objects as go\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josele/Library/CloudStorage/GoogleDrive-ejdvc757@gmail.com/Other computers/My MacBook Pro/PhD/HG_SWOT/Hypsometry/Hypsometry_project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the current working directory\n",
    "#os.chdir(\"..\") Used only fto go down one directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_010_022_NA_20240125T182836_20240125T182847_PIC0_01/SWOT_L2_HR_RiverSP_Node_010_022_NA_20240125T182836_20240125T182847_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_007_022_NA_20231124T041320_20231124T041331_PIC0_01/SWOT_L2_HR_RiverSP_Node_007_022_NA_20231124T041320_20231124T041331_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_008_535_SA_20240102T090319_20240102T090321_PIC0_01/SWOT_L2_HR_RiverSP_Node_008_535_SA_20240102T090319_20240102T090321_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_009_022_NA_20240104T214331_20240104T214342_PIC0_01/SWOT_L2_HR_RiverSP_Node_009_022_NA_20240104T214331_20240104T214342_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_008_022_NA_20231215T005824_20231215T005835_PIC0_01/SWOT_L2_HR_RiverSP_Node_008_022_NA_20231215T005824_20231215T005835_PIC0_01.shp'],\n",
       " ['SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Reach_008_022_NA_20231215T005824_20231215T005835_PIC0_01/SWOT_L2_HR_RiverSP_Reach_008_022_NA_20231215T005824_20231215T005835_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Reach_008_535_SA_20240102T090319_20240102T090321_PIC0_01/SWOT_L2_HR_RiverSP_Reach_008_535_SA_20240102T090319_20240102T090321_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Reach_009_022_NA_20240104T214331_20240104T214342_PIC0_01/SWOT_L2_HR_RiverSP_Reach_009_022_NA_20240104T214331_20240104T214342_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Reach_007_022_NA_20231124T041320_20231124T041331_PIC0_01/SWOT_L2_HR_RiverSP_Reach_007_022_NA_20231124T041320_20231124T041331_PIC0_01.shp',\n",
       "  'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Reach_010_022_NA_20240125T182836_20240125T182847_PIC0_01/SWOT_L2_HR_RiverSP_Reach_010_022_NA_20240125T182836_20240125T182847_PIC0_01.shp'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List all the shapefiles in the directory and split them into nodes and reaches\n",
    "shpNd = glob.glob('SWOT_L2_HR_RiverSP/**/*Node*.shp', recursive=True) #Nodes\n",
    "shpRch = glob.glob('SWOT_L2_HR_RiverSP/**/*Reach*.shp', recursive=True) #Reaches\n",
    "shpNd,shpRch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_010_022_NA_20240125T182836_20240125T182847_PIC0_01/SWOT_L2_HR_RiverSP_Node_010_022_NA_20240125T182836_20240125T182847_PIC0_01.shp',\n",
       " 'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_007_022_NA_20231124T041320_20231124T041331_PIC0_01/SWOT_L2_HR_RiverSP_Node_007_022_NA_20231124T041320_20231124T041331_PIC0_01.shp',\n",
       " 'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_009_022_NA_20240104T214331_20240104T214342_PIC0_01/SWOT_L2_HR_RiverSP_Node_009_022_NA_20240104T214331_20240104T214342_PIC0_01.shp',\n",
       " 'SWOT_L2_HR_RiverSP/SWOT_L2_HR_RiverSP_Node_008_022_NA_20231215T005824_20231215T005835_PIC0_01/SWOT_L2_HR_RiverSP_Node_008_022_NA_20231215T005824_20231215T005835_PIC0_01.shp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shpNd_022_NA = glob.glob('SWOT_L2_HR_RiverSP/**/*Node*_022_NA*.shp', recursive=True) #Nodes\n",
    "shpNd_022_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodataframes = []\n",
    "for i in range(len(shpNd_022_NA)):\n",
    "   geodataframes.append(gpd.read_file(shpNd_022_NA[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetted_dataframes = []\n",
    "\n",
    "# Loop over the list of dataframes\n",
    "for dataframe in geodataframes:\n",
    "\n",
    "    # Subset the dataframe to the desired columns and append to the list\n",
    "    subsetted_dataframes.append(dataframe[['node_id', 'lat', 'lon', 'river_name', 'wse', 'width']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          node_id        lat         lon river_name        wse         width\n",
      "0  71185300010013  55.718279 -106.423744    no_data  382.23556 -1.000000e+12\n",
      "0  71185300010013  55.718060 -106.423609    no_data  382.77604 -1.000000e+12\n",
      "0  71185300010013  55.718271 -106.423824    no_data  382.34443 -1.000000e+12\n",
      "0  71185300010013  55.718221 -106.423538    no_data  382.39953 -1.000000e+12\n"
     ]
    }
   ],
   "source": [
    "#Get the first row of each dataframe\n",
    "rows = [df.loc[0] for df in subsetted_dataframes]\n",
    "\n",
    "#Create a new dataframe with the first row of each dataframe\n",
    "rows = pd.DataFrame(rows)\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node_id       71185300010013\n",
       "lat                55.718279\n",
       "lon              -106.423744\n",
       "river_name           no_data\n",
       "wse                382.23556\n",
       "width        -999999999999.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows2 = []\n",
    "index = 0\n",
    "for df3 in subsetted_dataframes:\n",
    "    rows2.append(df3.loc[index])\n",
    "    index += 1\n",
    "#rows2 = pd.DataFrame(rows2)\n",
    "rows2[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45015"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsetted_dataframes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(Nodes[0]).get('width').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames={}\n",
    "for i in range(len(shpNd_022_NA)):\n",
    "        frames[i] = pd.concat([gpd.read_file(shpNd_022_NA[i]).get('node_id'), gpd.read_file(shpNd_022_NA[i]).get('river_name'), gpd.read_file(shpNd_022_NA[i]).get('lat'), \n",
    "        gpd.read_file(shpNd_022_NA[i]).get('lon'), gpd.read_file(shpNd_022_NA[i]).get('wse'), gpd.read_file(shpNd_022_NA[i]).get('width')], axis=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rows = [frames.iloc[0] for frames in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the shapefile. [0] is used to read the first shapefile in the list\n",
    "gpd.read_file(shpNd[1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gpd.read_file(shpNd[0]).explore('wse', cmap='viridis', legend=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWOT_HR_shp1 = gpd.read_file(shpNd[0])[['river_name','p_wse','p_width','geometry']]\n",
    "SWOT_HR_shp1 =SWOT_HR_shp1.rename(columns={'river_name': 'River Name','p_wse':'Water Surface Elevation','p_width':'River Width'})\n",
    "SWOT_HR_shp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = SWOT_HR_shp1\n",
    "updated_m = L.explore(column='Water Surface Elevation', cmap='viridis', legend=True)\n",
    "\n",
    "updated_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.crs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"**/*\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes =   glob.glob(os.path.join('SWOT_L2_HR_RiverSP','*','*.shp'))\n",
    "list_of_dfs = []\n",
    "for f in shapes:\n",
    "    df = gpd.read_file(f)\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "list_of_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypsometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
